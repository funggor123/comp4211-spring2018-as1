\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2017
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2017}


% to compile a camera-ready version, add the [final] option, e.g.:
% \usepackage[final]{nips_2017}

\usepackage[final]{nips_2018}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}

\title{COMP 4211 - Machine Learning Programming Assignment 1 Report}

\author{%
	Cheng Chi Fung \\
	\texttt{cfchengac@connect.ust.hk} \\
}

\begin{document}

\maketitle

\begin{abstract}
  In this assignment, we used linear regression, logistic regression and single layer neural network to perform the regression and classification on three binary classification and regression data sets.
  
\end{abstract}

\section{Linear Regression}

\subsection{Experienment Model Settings}

For linear regression, we used the built-in models   \textbf{LinearRegression} in skitlearn to perform the linear regression on three regression datasets .This model fits a linear model with coefficients  	$w = (w_1,..., w_p)$  to minimize the residual sum of squares between the observed responses in the dataset, and the responses predicted by the linear approximation. This model has \textbf{no hyperparameter} to set.

\begin{table}[htb]
	\caption{Experiments Datasets Settings}
	\label{sample-table}
	\centering
	\begin{tabular}{lll}
		\toprule
		\cmidrule{1-3}
		Dataset & Training set & Test set \\
		\midrule
		Fifa & $13191$ & $4397$ \\
		Finance & $2754$ & $918$ \\
		Orbits & $9642$ & $3215$ \\
		\bottomrule
	\end{tabular}
\end{table}

\subsection{Experiment Results}

The following are the experiment results which using the above model setting on fifa, finanace and orbits regression datasets.

\begin{table}[htb]
	\caption{Experiments Results of Linear Regression on three Regression Datasets}
	\label{sample-table}
	\centering
	\begin{tabular}{lll}
		\toprule
		\cmidrule{1-3}
		\multicolumn{3}{c}{Sum of Squared Error (Mean)}\\
		\midrule
		Dataset & Training set & Test set \\
		\midrule
		Fifa & $1583.01911$ ($0.12000$) & $535.36126$ ($0.12175$) \\
		Finance & $394.91758$ ($0.14339$) & $163.38803$ ($0.17798$) \\
		Orbits & $917.91272$ ($0.09519$) & $311.47817$ ($0.09688$)  \\
		\bottomrule
	\end{tabular}
\end{table}

From the experiment results, we found out that excepts the \textbf{finance} datasets, the mean squared error of the training set and test set are almost the same. And, for the finance datasets, the mean squared error of the test set (0.17798) are a much higher than the training set (0.14339). It means that this model may \textbf{overrfit} the training data of the finance datasets.

\section{Logistic Regression}

\subsection{Experienmental Model Settings}

To perform the logistic regression with gradient-descent algorithm by minimizing the cross-entropy loss on the three classification datasets,  we used the built-in model \textbf{SGDClassifier} in skitlearn. This model implements regularized linear models with \textbf{stochastic gradient descent} (SGD) learning. 

\pagebreak

To get better training results, we performed the \textbf{hyperparameters tunning} by using \textbf{GridSearchCV} in skitlearn to obtain best hyperparameters parameters for each datasets. The following are the settings of parameters tuning.

\begin{table}[htb]
	\caption{Parameters Tuning Settings (Tuned hyperparameters *)}
	\label{sample-table}
	\centering
	\begin{tabular}{lll}
		\toprule
		\cmidrule{1-2}
		Name     &  Parameter Setttings	\\
		\midrule
		max\_iter 		  & 	$5000$  \\
		tol      	          & 	  $0.000000001$        \\
		learning\_rate* 		  & 	$0.1, 0.01,  0.001$    \\
		number of cross folds		  &   $5$     \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[htb]
	\caption{The results of the Hyperparameters Tuning}
	\label{sample-table}
	\centering
	\begin{tabular}{lll}
		\toprule
		\cmidrule{1-2}
		Name     &  Parameter Setttings	\\
		\midrule
		max\_iter 		  & 	$5000$  \\
		tol      	          & 	  $0.000000001$        \\
		learning\_rate* 		  & 	$0.1, 0.01,  0.001$    \\
		number of cross folds		  &   $5$     \\
		\bottomrule
	\end{tabular}
\end{table}



\subsection{Experiment Results}

The following are the experiment results which using the above model setting on fifa, finanace and orbits classification datasets.



\section{Sinlge Layer Neural Network}

\subsection{Experienmental Model Settings}

To perform the logistic regression with gradient-descent algorithm by minimizing the cross-entropy loss on the three classification datasets,  we used the built-in model \textbf{SGDClassifier} in skitlearn. This model implements regularized linear models with \textbf{stochastic gradient descent} (SGD) learning. 

\subsection{Experienment Results}



\end{document}

